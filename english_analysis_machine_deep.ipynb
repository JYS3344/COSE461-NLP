{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "english_analysis_machine_deep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm0uQZ05j8kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBNxOWutj8kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load data from json.\n",
        "#Data has string and target has category.\n",
        "train_X_original = []\n",
        "train_Y = []\n",
        "test_X_original = []\n",
        "test_Y = []\n",
        "\n",
        "###########################################################\n",
        "#                                                         #\n",
        "# CHANGE path_dir to EmotionLines directory               #\n",
        "# It should end with '/'                                  #\n",
        "###########################################################\n",
        "path_dir = 'drive/My Drive/ColabNotebooks/English/EmotionLines/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dict_emotion_value = { 'joy':0, 'neutral' : 1,'anger':2, 'disgust':3, 'sadness':4, 'surprise':5, 'fear':6, 'non-neutral':7}\n",
        "with open(path_dir+'Friends/friends_train.json') as train_file:\n",
        "    train_data = json.load(train_file)\n",
        "    for episode in train_data:\n",
        "        for phrase in episode:\n",
        "            train_X_original.append(phrase['utterance'])\n",
        "            train_Y.append(dict_emotion_value[phrase['emotion']])\n",
        "with open(path_dir + 'Friends/friends_test.json') as test_file:\n",
        "    test_data = json.load(test_file)\n",
        "    for episode in test_data:\n",
        "        for phrase in episode:\n",
        "            test_X_original.append(phrase['utterance'])\n",
        "            test_Y.append(dict_emotion_value[phrase['emotion']])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxSa1CSbbx5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "60901440-3b8f-4889-9c74-181f94bcb255"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "import nltk\n",
        "#from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdr8xj0zfImx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "def preprocess(words):\n",
        "    documents = []\n",
        "    wnl = WordNetLemmatizer()\n",
        "    for sen in range(0, len(words)):\n",
        "        # Remove all the special characters\n",
        "        document = re.sub(r'\\W', ' ', str(words[sen]))\n",
        "        # remove all single characters\n",
        "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "        # Remove single characters from the start\n",
        "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "        # Substituting multiple spaces with single space\n",
        "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "        # Converting to Lowercase\n",
        "        document = document.lower()\n",
        "        # Lemmatization\n",
        "        document = document.split()\n",
        "        document = [wnl.lemmatize(word) for word in document]\n",
        "        result = []\n",
        "        for word in document: \n",
        "            if word not in stop_words:\n",
        "                result.append(word)\n",
        "        document = result\n",
        "        document = ' '.join(document)\n",
        "        documents.append(document)\n",
        "    return documents\n",
        "\n",
        "\n",
        "train_X = preprocess(train_X_original)\n",
        "test_X = preprocess(test_X_original)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQt3GRSmj8k5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15d64bcc-1a65-4fa5-fb6e-c7bf62d5e87e"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "class DenseTransformer(TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, **fit_params):\n",
        "        return X.todense()\n",
        "\n",
        "clfs = []\n",
        "\n",
        "\n",
        "#Naive bayes with pipeline(It is in practice video)\n",
        "clfs.append( Pipeline([('vect',TfidfVectorizer()),('clf',MultinomialNB())]) )\n",
        "\n",
        "#Support vector classifier(support vector machine)\n",
        "clfs.append( Pipeline([('vect',TfidfVectorizer()),('clf',svm.SVC(kernel='linear',probability=True))]) )\n",
        "clfs.append( Pipeline([('vect',TfidfVectorizer()),('clf',svm.SVC(kernel='poly',probability=True))]) )\n",
        "clfs.append( Pipeline([('vect',TfidfVectorizer()),('clf',svm.SVC(kernel='rbf',probability=True))]) )\n",
        "clfs.append( Pipeline([('vect',TfidfVectorizer()),('clf',svm.SVC(kernel='sigmoid',probability=True))]) )\n",
        "\n",
        "#Stochastic gradient descent\n",
        "clfs.append( Pipeline([('vect',TfidfVectorizer()),('clf',CalibratedClassifierCV(base_estimator=SGDClassifier(loss='modified_huber'), cv=5, method='isotonic'))]) )\n",
        "\n",
        "#Random Forest Classifier\n",
        "clfs.append( Pipeline([('tfidf',TfidfVectorizer()),('to_dense', DenseTransformer()), ('rfc',RandomForestClassifier(n_estimators=500))]) )\n",
        "\n",
        "#K-Neighbor classifier)\n",
        "clfs.append( Pipeline([('tfidf',TfidfVectorizer()),('to_dense', DenseTransformer()),('clf',KNeighborsClassifier(n_neighbors=16,algorithm='brute'))]) )\n",
        "\n",
        "#Decision Tree Classifier\n",
        "clfs.append( Pipeline([('tfidf',TfidfVectorizer()),('clf', DecisionTreeClassifier(max_depth=16))]) )\n",
        "\n",
        "#AdaBoost Classifier\n",
        "clfs.append( Pipeline([('tfidf',TfidfVectorizer()),('clf', AdaBoostClassifier() )]) )\n",
        "\n",
        "print(len(clfs))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-JYrb-SmKzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5be6ca1-f90a-4977-8442-75dfb2542a72"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import sklearn.metrics as metrics\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "\n",
        "\n",
        "def print_prediction(clf,words,target):\n",
        "    start = timer()\n",
        "    prediction = clf.predict(words)\n",
        "    end = timer()\n",
        "    print(end - start)\n",
        "    result = np.mean(prediction==target)\n",
        "    print(result)\n",
        "    print('accuracy', metrics.accuracy_score(prediction,target) )\n",
        "    print('precision', metrics.precision_score(prediction,target,average='micro') )\n",
        "    print('recall', metrics.recall_score(prediction,target,average='micro') )\n",
        "    print('f1', metrics.f1_score(prediction,target,average='micro') )\n",
        "    print(metrics.classification_report(prediction,target,zero_division=0))\n",
        "\n",
        "for clf in clfs:\n",
        "  clf.fit(train_X,train_Y)\n",
        "  print_prediction(clf,test_X,test_Y)\n",
        "  predict = clf.predict_proba(test_X)\n",
        "  if predict.shape[1] != 8:\n",
        "      print('NOT 8!')\n",
        "      break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.016010851000032744\n",
            "0.4829956584659913\n",
            "accuracy 0.4829956584659913\n",
            "precision 0.4829956584659913\n",
            "recall 0.4829956584659913\n",
            "f1 0.4829956584659913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.60      0.06        15\n",
            "           1       0.99      0.48      0.65      2622\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.12      0.72      0.20        46\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.04      0.27      0.07        81\n",
            "\n",
            "    accuracy                           0.48      2764\n",
            "   macro avg       0.15      0.26      0.12      2764\n",
            "weighted avg       0.94      0.48      0.62      2764\n",
            "\n",
            "1.2756925370000545\n",
            "0.5\n",
            "accuracy 0.5\n",
            "precision 0.5\n",
            "recall 0.5\n",
            "f1 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.51      0.29       122\n",
            "           1       0.92      0.51      0.66      2319\n",
            "           2       0.01      0.20      0.01         5\n",
            "           3       0.07      0.62      0.13         8\n",
            "           4       0.13      0.69      0.22        16\n",
            "           5       0.23      0.59      0.33       111\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.09      0.27      0.14       183\n",
            "\n",
            "    accuracy                           0.50      2764\n",
            "   macro avg       0.21      0.42      0.22      2764\n",
            "weighted avg       0.80      0.50      0.59      2764\n",
            "\n",
            "1.419560163999904\n",
            "0.48516642547033284\n",
            "accuracy 0.48516642547033284\n",
            "precision 0.48516642547033284\n",
            "recall 0.48516642547033284\n",
            "f1 0.48516642547033284\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.54      0.20        68\n",
            "           1       0.93      0.49      0.65      2419\n",
            "           2       0.04      0.32      0.07        19\n",
            "           3       0.04      0.75      0.08         4\n",
            "           4       0.07      0.55      0.12        11\n",
            "           5       0.22      0.57      0.32       110\n",
            "           6       0.03      0.14      0.05         7\n",
            "           7       0.05      0.23      0.09       126\n",
            "\n",
            "    accuracy                           0.49      2764\n",
            "   macro avg       0.19      0.45      0.20      2764\n",
            "weighted avg       0.83      0.49      0.59      2764\n",
            "\n",
            "1.8542800079999324\n",
            "0.5007235890014472\n",
            "accuracy 0.5007235890014472\n",
            "precision 0.5007235890014472\n",
            "recall 0.5007235890014472\n",
            "f1 0.5007235890014472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.54      0.28       106\n",
            "           1       0.94      0.51      0.66      2388\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.04      0.60      0.08         5\n",
            "           4       0.12      0.71      0.20        14\n",
            "           5       0.21      0.66      0.32        93\n",
            "           6       0.03      0.33      0.06         3\n",
            "           7       0.08      0.27      0.12       154\n",
            "\n",
            "    accuracy                           0.50      2764\n",
            "   macro avg       0.20      0.45      0.21      2764\n",
            "weighted avg       0.83      0.50      0.60      2764\n",
            "\n",
            "1.3338908099999571\n",
            "0.4667149059334298\n",
            "accuracy 0.4667149059334298\n",
            "precision 0.4667149059334298\n",
            "recall 0.4667149059334298\n",
            "f1 0.4667149059334298\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.40      0.29       179\n",
            "           1       0.83      0.50      0.63      2126\n",
            "           2       0.01      0.33      0.01         3\n",
            "           3       0.04      0.50      0.08         6\n",
            "           4       0.13      0.65      0.22        17\n",
            "           5       0.20      0.45      0.27       124\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.14      0.24      0.18       309\n",
            "\n",
            "    accuracy                           0.47      2764\n",
            "   macro avg       0.20      0.38      0.21      2764\n",
            "weighted avg       0.68      0.47      0.54      2764\n",
            "\n",
            "0.028503266999905463\n",
            "0.4934876989869754\n",
            "accuracy 0.4934876989869754\n",
            "precision 0.4934876989869754\n",
            "recall 0.4934876989869754\n",
            "f1 0.4934876989869754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.41      0.22       109\n",
            "           1       0.94      0.50      0.66      2409\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.03      1.00      0.06         2\n",
            "           4       0.09      0.47      0.16        17\n",
            "           5       0.23      0.59      0.34       114\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.05      0.25      0.09       111\n",
            "\n",
            "    accuracy                           0.49      2764\n",
            "   macro avg       0.19      0.40      0.19      2764\n",
            "weighted avg       0.84      0.49      0.60      2764\n",
            "\n",
            "4.324075588999904\n",
            "0.4833574529667149\n",
            "accuracy 0.4833574529667149\n",
            "precision 0.4833574529667149\n",
            "recall 0.4833574529667149\n",
            "f1 0.4833574529667149\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.47      0.31       150\n",
            "           1       0.86      0.52      0.64      2132\n",
            "           2       0.06      0.32      0.10        31\n",
            "           3       0.06      0.27      0.10        15\n",
            "           4       0.14      0.48      0.22        25\n",
            "           5       0.28      0.45      0.35       177\n",
            "           6       0.03      0.17      0.05         6\n",
            "           7       0.11      0.25      0.15       228\n",
            "\n",
            "    accuracy                           0.48      2764\n",
            "   macro avg       0.22      0.37      0.24      2764\n",
            "weighted avg       0.70      0.48      0.55      2764\n",
            "\n",
            "9.40689078399987\n",
            "0.4475397973950796\n",
            "accuracy 0.4475397973950796\n",
            "precision 0.4475397973950796\n",
            "recall 0.4475397973950796\n",
            "f1 0.4475397973950796\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.44      0.17        72\n",
            "           1       0.84      0.50      0.63      2171\n",
            "           2       0.01      0.33      0.02         6\n",
            "           3       0.03      0.50      0.06         4\n",
            "           4       0.11      0.69      0.18        13\n",
            "           5       0.29      0.21      0.24       392\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.05      0.24      0.08       105\n",
            "\n",
            "    accuracy                           0.45      2764\n",
            "   macro avg       0.18      0.36      0.17      2764\n",
            "weighted avg       0.71      0.45      0.54      2764\n",
            "\n",
            "0.016406305999908\n",
            "0.49384949348769897\n",
            "accuracy 0.49384949348769897\n",
            "precision 0.49384949348769897\n",
            "recall 0.49384949348769897\n",
            "f1 0.49384949348769897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.45      0.20        88\n",
            "           1       0.96      0.49      0.65      2515\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.15      0.45      0.23        29\n",
            "           5       0.20      0.68      0.31        85\n",
            "           6       0.03      0.17      0.05         6\n",
            "           7       0.03      0.37      0.05        38\n",
            "\n",
            "    accuracy                           0.49      2764\n",
            "   macro avg       0.19      0.33      0.19      2764\n",
            "weighted avg       0.89      0.49      0.61      2764\n",
            "\n",
            "0.06975632100011353\n",
            "0.49384949348769897\n",
            "accuracy 0.49384949348769897\n",
            "precision 0.49384949348769897\n",
            "recall 0.49384949348769897\n",
            "f1 0.49384949348769897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.57      0.24        81\n",
            "           1       0.95      0.49      0.65      2475\n",
            "           2       0.01      0.50      0.01         2\n",
            "           3       0.07      0.36      0.12        14\n",
            "           4       0.16      0.35      0.22        40\n",
            "           5       0.21      0.62      0.31        95\n",
            "           6       0.03      0.10      0.05        10\n",
            "           7       0.03      0.34      0.05        47\n",
            "\n",
            "    accuracy                           0.49      2764\n",
            "   macro avg       0.20      0.42      0.21      2764\n",
            "weighted avg       0.87      0.49      0.60      2764\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsdJNcbOPkzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "870ebd09-b0e5-44f0-88ec-6752ad914f5e"
      },
      "source": [
        "predicts = []\n",
        "for clf in clfs:\n",
        "  predict = clf.predict_proba(train_X)\n",
        "  print('One prediction ended')\n",
        "  if predict.shape[1] != 8:\n",
        "      print('NOT 8!')\n",
        "      break\n",
        "  predicts.append(predict)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20QfzNQTxT46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a8c0590-e1d6-45bd-da66-ecf425d89ed8"
      },
      "source": [
        "np_predicts = np.swapaxes(np.array(predicts),0,1)\n",
        "print(np_predicts.shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10561, 10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK8_tEvXEJjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "fc904e46-74ad-43c1-c77d-96cc3d7fccd7"
      },
      "source": [
        "test_predicts = []\n",
        "for clf in clfs:\n",
        "  test_predict = clf.predict_proba(test_X)\n",
        "  print('One prediction ended')\n",
        "  if test_predict.shape[1] != 8:\n",
        "      print('NOT 8!')\n",
        "      break\n",
        "  test_predicts.append(test_predict)\n",
        "test_np_predicts = np.swapaxes(np.array(test_predicts),0,1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n",
            "One prediction ended\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qeEcDxiD-A1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "af7aed7d-8a89-4cb3-b83a-8fb2c022a679"
      },
      "source": [
        "from keras.layers import Reshape, Conv2D,Conv1D, GlobalMaxPooling2D,LSTM,MaxPooling1D,Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adagrad,RMSprop\n",
        "def imdb_cnn_2():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(2048, len(clfs), activation='relu',input_shape=(len(clfs),8)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dense(32,activation='softmax'))\n",
        "    \n",
        "    opt = Adagrad(lr = 0.008)\n",
        "    model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "model = imdb_cnn_2()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 1, 2048)           165888    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                8224      \n",
            "=================================================================\n",
            "Total params: 1,354,528\n",
            "Trainable params: 1,354,528\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc9BFiKij8mO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc00741c-a4f8-4421-e533-74cea8caef71"
      },
      "source": [
        "model.fit(np_predicts, train_Y, epochs=100,validation_split=0.2,verbose=2)#, verbose=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8448 samples, validate on 2113 samples\n",
            "Epoch 1/100\n",
            " - 5s - loss: 0.5847 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.3249 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 2/100\n",
            " - 5s - loss: 0.3651 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.3111 - val_sparse_categorical_accuracy: 0.8949\n",
            "Epoch 3/100\n",
            " - 5s - loss: 0.3487 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.3153 - val_sparse_categorical_accuracy: 0.8935\n",
            "Epoch 4/100\n",
            " - 5s - loss: 0.3413 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.3132 - val_sparse_categorical_accuracy: 0.8911\n",
            "Epoch 5/100\n",
            " - 5s - loss: 0.3305 - sparse_categorical_accuracy: 0.8834 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.8959\n",
            "Epoch 6/100\n",
            " - 5s - loss: 0.3289 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.2963 - val_sparse_categorical_accuracy: 0.8945\n",
            "Epoch 7/100\n",
            " - 5s - loss: 0.3236 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.2978 - val_sparse_categorical_accuracy: 0.8935\n",
            "Epoch 8/100\n",
            " - 5s - loss: 0.3203 - sparse_categorical_accuracy: 0.8852 - val_loss: 0.2986 - val_sparse_categorical_accuracy: 0.8959\n",
            "Epoch 9/100\n",
            " - 5s - loss: 0.3177 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.2963 - val_sparse_categorical_accuracy: 0.8959\n",
            "Epoch 10/100\n",
            " - 5s - loss: 0.3137 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.2943 - val_sparse_categorical_accuracy: 0.8940\n",
            "Epoch 11/100\n",
            " - 5s - loss: 0.3127 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8949\n",
            "Epoch 12/100\n",
            " - 5s - loss: 0.3129 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.8940\n",
            "Epoch 13/100\n",
            " - 5s - loss: 0.3113 - sparse_categorical_accuracy: 0.8857 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.8949\n",
            "Epoch 14/100\n",
            " - 5s - loss: 0.3107 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.2994 - val_sparse_categorical_accuracy: 0.8916\n",
            "Epoch 15/100\n",
            " - 5s - loss: 0.3060 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.3033 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 16/100\n",
            " - 5s - loss: 0.3097 - sparse_categorical_accuracy: 0.8860 - val_loss: 0.2991 - val_sparse_categorical_accuracy: 0.8916\n",
            "Epoch 17/100\n",
            " - 5s - loss: 0.3095 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.2969 - val_sparse_categorical_accuracy: 0.8911\n",
            "Epoch 18/100\n",
            " - 5s - loss: 0.3069 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.2990 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 19/100\n",
            " - 5s - loss: 0.3045 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.2973 - val_sparse_categorical_accuracy: 0.8930\n",
            "Epoch 20/100\n",
            " - 5s - loss: 0.3043 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.8921\n",
            "Epoch 21/100\n",
            " - 5s - loss: 0.3034 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8949\n",
            "Epoch 22/100\n",
            " - 5s - loss: 0.2999 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.2956 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 23/100\n",
            " - 5s - loss: 0.3005 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.2966 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 24/100\n",
            " - 5s - loss: 0.2998 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8926\n",
            "Epoch 25/100\n",
            " - 5s - loss: 0.2997 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2973 - val_sparse_categorical_accuracy: 0.8916\n",
            "Epoch 26/100\n",
            " - 5s - loss: 0.2997 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8916\n",
            "Epoch 27/100\n",
            " - 5s - loss: 0.2995 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.2978 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 28/100\n",
            " - 5s - loss: 0.2956 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.2961 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 29/100\n",
            " - 5s - loss: 0.2983 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.2979 - val_sparse_categorical_accuracy: 0.8916\n",
            "Epoch 30/100\n",
            " - 5s - loss: 0.2978 - sparse_categorical_accuracy: 0.8857 - val_loss: 0.2986 - val_sparse_categorical_accuracy: 0.8940\n",
            "Epoch 31/100\n",
            " - 5s - loss: 0.2993 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.2979 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 32/100\n",
            " - 4s - loss: 0.2950 - sparse_categorical_accuracy: 0.8868 - val_loss: 0.2929 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 33/100\n",
            " - 4s - loss: 0.2959 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.2968 - val_sparse_categorical_accuracy: 0.8911\n",
            "Epoch 34/100\n",
            " - 4s - loss: 0.2940 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.2973 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 35/100\n",
            " - 4s - loss: 0.2949 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.2957 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 36/100\n",
            " - 4s - loss: 0.2927 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.3008 - val_sparse_categorical_accuracy: 0.8859\n",
            "Epoch 37/100\n",
            " - 4s - loss: 0.2947 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.2955 - val_sparse_categorical_accuracy: 0.8911\n",
            "Epoch 38/100\n",
            " - 4s - loss: 0.2912 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2942 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 39/100\n",
            " - 5s - loss: 0.2930 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 40/100\n",
            " - 5s - loss: 0.2948 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.2960 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 41/100\n",
            " - 5s - loss: 0.2929 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2950 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 42/100\n",
            " - 4s - loss: 0.2920 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.2947 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 43/100\n",
            " - 4s - loss: 0.2917 - sparse_categorical_accuracy: 0.8855 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 44/100\n",
            " - 5s - loss: 0.2926 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.2957 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 45/100\n",
            " - 4s - loss: 0.2910 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 46/100\n",
            " - 4s - loss: 0.2909 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.2978 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 47/100\n",
            " - 5s - loss: 0.2919 - sparse_categorical_accuracy: 0.8868 - val_loss: 0.2982 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 48/100\n",
            " - 5s - loss: 0.2913 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 49/100\n",
            " - 5s - loss: 0.2925 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.2961 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 50/100\n",
            " - 4s - loss: 0.2907 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 51/100\n",
            " - 4s - loss: 0.2921 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.2968 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 52/100\n",
            " - 4s - loss: 0.2895 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.2970 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 53/100\n",
            " - 4s - loss: 0.2903 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.2992 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 54/100\n",
            " - 5s - loss: 0.2898 - sparse_categorical_accuracy: 0.8868 - val_loss: 0.2960 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 55/100\n",
            " - 5s - loss: 0.2887 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 56/100\n",
            " - 4s - loss: 0.2890 - sparse_categorical_accuracy: 0.8870 - val_loss: 0.2989 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 57/100\n",
            " - 4s - loss: 0.2876 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.2987 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 58/100\n",
            " - 5s - loss: 0.2889 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 59/100\n",
            " - 5s - loss: 0.2883 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.2980 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 60/100\n",
            " - 4s - loss: 0.2850 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.2997 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 61/100\n",
            " - 4s - loss: 0.2876 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.2976 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 62/100\n",
            " - 4s - loss: 0.2880 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 63/100\n",
            " - 4s - loss: 0.2867 - sparse_categorical_accuracy: 0.8899 - val_loss: 0.2958 - val_sparse_categorical_accuracy: 0.8888\n",
            "Epoch 64/100\n",
            " - 4s - loss: 0.2863 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.2965 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 65/100\n",
            " - 4s - loss: 0.2851 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.2981 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 66/100\n",
            " - 4s - loss: 0.2880 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 67/100\n",
            " - 5s - loss: 0.2883 - sparse_categorical_accuracy: 0.8868 - val_loss: 0.2976 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 68/100\n",
            " - 5s - loss: 0.2871 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.2978 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 69/100\n",
            " - 5s - loss: 0.2852 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 70/100\n",
            " - 4s - loss: 0.2873 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2970 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 71/100\n",
            " - 4s - loss: 0.2878 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.8926\n",
            "Epoch 72/100\n",
            " - 4s - loss: 0.2884 - sparse_categorical_accuracy: 0.8902 - val_loss: 0.2970 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 73/100\n",
            " - 4s - loss: 0.2839 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 74/100\n",
            " - 4s - loss: 0.2873 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 75/100\n",
            " - 4s - loss: 0.2842 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.2987 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 76/100\n",
            " - 4s - loss: 0.2850 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.2993 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 77/100\n",
            " - 4s - loss: 0.2860 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.8859\n",
            "Epoch 78/100\n",
            " - 4s - loss: 0.2853 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2968 - val_sparse_categorical_accuracy: 0.8864\n",
            "Epoch 79/100\n",
            " - 4s - loss: 0.2857 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.2983 - val_sparse_categorical_accuracy: 0.8864\n",
            "Epoch 80/100\n",
            " - 5s - loss: 0.2840 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.3010 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 81/100\n",
            " - 5s - loss: 0.2840 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.2990 - val_sparse_categorical_accuracy: 0.8897\n",
            "Epoch 82/100\n",
            " - 5s - loss: 0.2849 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.2988 - val_sparse_categorical_accuracy: 0.8855\n",
            "Epoch 83/100\n",
            " - 5s - loss: 0.2863 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 84/100\n",
            " - 5s - loss: 0.2847 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.2979 - val_sparse_categorical_accuracy: 0.8864\n",
            "Epoch 85/100\n",
            " - 5s - loss: 0.2841 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.3002 - val_sparse_categorical_accuracy: 0.8855\n",
            "Epoch 86/100\n",
            " - 5s - loss: 0.2860 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.2980 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 87/100\n",
            " - 5s - loss: 0.2842 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.2987 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 88/100\n",
            " - 5s - loss: 0.2842 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 89/100\n",
            " - 4s - loss: 0.2835 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.2992 - val_sparse_categorical_accuracy: 0.8855\n",
            "Epoch 90/100\n",
            " - 5s - loss: 0.2839 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.8855\n",
            "Epoch 91/100\n",
            " - 4s - loss: 0.2846 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 92/100\n",
            " - 4s - loss: 0.2837 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 93/100\n",
            " - 4s - loss: 0.2829 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.3007 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 94/100\n",
            " - 5s - loss: 0.2849 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.2994 - val_sparse_categorical_accuracy: 0.8859\n",
            "Epoch 95/100\n",
            " - 5s - loss: 0.2828 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.2991 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 96/100\n",
            " - 5s - loss: 0.2813 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.8859\n",
            "Epoch 97/100\n",
            " - 4s - loss: 0.2828 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 98/100\n",
            " - 4s - loss: 0.2830 - sparse_categorical_accuracy: 0.8905 - val_loss: 0.2997 - val_sparse_categorical_accuracy: 0.8864\n",
            "Epoch 99/100\n",
            " - 4s - loss: 0.2842 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.3004 - val_sparse_categorical_accuracy: 0.8869\n",
            "Epoch 100/100\n",
            " - 4s - loss: 0.2831 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.3002 - val_sparse_categorical_accuracy: 0.8864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc53a192748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPEqVrXmB5GW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "dc890e08-e25e-47a1-9515-ff725d930b40"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(test_np_predicts, test_Y, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "prediction = model.predict(test_np_predicts)\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "target_names = ['joy', 'neutral','anger', 'disgust', 'sadness', 'surprise', 'fear', 'non-neutral']\n",
        "print(prediction)\n",
        "print(classification_report(predicted_classes,test_Y,zero_division=0,target_names=target_names))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 47.793055\n",
            "[[1.5285605e-02 7.2882867e-01 5.8721830e-03 ... 7.1102448e-07\n",
            "  7.3885087e-07 6.9889910e-07]\n",
            " [3.9769458e-03 9.2161888e-01 1.0011938e-03 ... 2.2660730e-07\n",
            "  1.8715198e-07 1.8382326e-07]\n",
            " [3.2354362e-02 7.5489539e-01 8.1709167e-03 ... 5.2129241e-07\n",
            "  7.4034511e-07 6.8227337e-07]\n",
            " ...\n",
            " [7.8376824e-01 9.5622800e-03 1.3346227e-01 ... 1.7042907e-05\n",
            "  3.0447040e-05 3.8440718e-05]\n",
            " [4.6413641e-02 4.6601933e-01 2.2804072e-02 ... 3.2028929e-06\n",
            "  4.3665109e-06 3.9157430e-06]\n",
            " [3.3127025e-03 5.5105609e-01 7.4579538e-04 ... 5.1499267e-08\n",
            "  4.2174783e-08 3.8607606e-08]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         joy       0.25      0.41      0.31       188\n",
            "     neutral       0.84      0.52      0.64      2066\n",
            "       anger       0.07      0.31      0.12        39\n",
            "     disgust       0.07      0.17      0.10        29\n",
            "     sadness       0.18      0.32      0.23        47\n",
            "    surprise       0.26      0.45      0.33       167\n",
            "        fear       0.03      0.11      0.05         9\n",
            " non-neutral       0.10      0.26      0.15       219\n",
            "\n",
            "    accuracy                           0.48      2764\n",
            "   macro avg       0.23      0.32      0.24      2764\n",
            "weighted avg       0.67      0.48      0.54      2764\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}